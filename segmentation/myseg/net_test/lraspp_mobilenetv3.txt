/home/fll/leo_test/federate/my_fedavg_seg

Experimental details:
    Model     : lraspp_mobilenetv3
    No of classes     : 21
    Optimizer : sgd
    Learning  : 0.05
    Global Rounds   : 1500

    Federated parameters:
    IID
    Fraction of users  : 0.035
    Local Batch size   : 8
    Local Epochs       : 2

device: cuda
find 2975 examples
find 1525 examples
LRASPP(
  (backbone): IntermediateLayerGetter(
    (0): ConvNormActivation(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): Hardswish()
    )
    (1): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (1): ConvNormActivation(
          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (2): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (1): ConvNormActivation(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (2): ConvNormActivation(
          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (3): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (1): ConvNormActivation(
          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (2): ConvNormActivation(
          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (4): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (1): ConvNormActivation(
          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (5): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (1): ConvNormActivation(
          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (6): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (1): ConvNormActivation(
          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Tanh()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (7): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): ConvNormActivation(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (8): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)
          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): ConvNormActivation(
          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (9): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)
          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): ConvNormActivation(
          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (10): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)
          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): ConvNormActivation(
          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (11): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (12): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)
          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (13): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=672, bias=False)
          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (14): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (15): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): ConvNormActivation(
          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))
          (activation): Tanh()
          (scale_activation): Hardsigmoid()
        )
        (3): ConvNormActivation(
          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (16): ConvNormActivation(
      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): Hardswish()
    )
  )
  (classifier): LRASPPHead(
    (cbr): Sequential(
      (0): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Tanh()
    )
    (scale): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): Sigmoid()
    )
    (low_classifier): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1))
    (high_classifier): Conv2d(128, 20, kernel_size=(1, 1), stride=(1, 1))
  )
)
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
LRASPP                                             --                        --
├─IntermediateLayerGetter: 1-1                     [1, 960, 32, 64]          --
│    └─ConvNormActivation: 2-1                     [1, 16, 256, 512]         --
│    │    └─Conv2d: 3-1                            [1, 16, 256, 512]         432
│    │    └─BatchNorm2d: 3-2                       [1, 16, 256, 512]         32
│    │    └─Hardswish: 3-3                         [1, 16, 256, 512]         --
│    └─InvertedResidual: 2-2                       [1, 16, 256, 512]         --
│    │    └─Sequential: 3-4                        [1, 16, 256, 512]         --
│    │    │    └─ConvNormActivation: 4-1           [1, 16, 256, 512]         --
│    │    │    │    └─Conv2d: 5-1                  [1, 16, 256, 512]         144
│    │    │    │    └─BatchNorm2d: 5-2             [1, 16, 256, 512]         32
│    │    │    │    └─Tanh: 5-3                    [1, 16, 256, 512]         --
│    │    │    └─ConvNormActivation: 4-2           [1, 16, 256, 512]         --
│    │    │    │    └─Conv2d: 5-4                  [1, 16, 256, 512]         256
│    │    │    │    └─BatchNorm2d: 5-5             [1, 16, 256, 512]         32
│    └─InvertedResidual: 2-3                       [1, 24, 128, 256]         --
│    │    └─Sequential: 3-5                        [1, 24, 128, 256]         --
│    │    │    └─ConvNormActivation: 4-3           [1, 64, 256, 512]         --
│    │    │    │    └─Conv2d: 5-6                  [1, 64, 256, 512]         1,024
│    │    │    │    └─BatchNorm2d: 5-7             [1, 64, 256, 512]         128
│    │    │    │    └─Tanh: 5-8                    [1, 64, 256, 512]         --
│    │    │    └─ConvNormActivation: 4-4           [1, 64, 128, 256]         --
│    │    │    │    └─Conv2d: 5-9                  [1, 64, 128, 256]         576
│    │    │    │    └─BatchNorm2d: 5-10            [1, 64, 128, 256]         128
│    │    │    │    └─Tanh: 5-11                   [1, 64, 128, 256]         --
│    │    │    └─ConvNormActivation: 4-5           [1, 24, 128, 256]         --
│    │    │    │    └─Conv2d: 5-12                 [1, 24, 128, 256]         1,536
│    │    │    │    └─BatchNorm2d: 5-13            [1, 24, 128, 256]         48
│    └─InvertedResidual: 2-4                       [1, 24, 128, 256]         --
│    │    └─Sequential: 3-6                        [1, 24, 128, 256]         --
│    │    │    └─ConvNormActivation: 4-6           [1, 72, 128, 256]         --
│    │    │    │    └─Conv2d: 5-14                 [1, 72, 128, 256]         1,728
│    │    │    │    └─BatchNorm2d: 5-15            [1, 72, 128, 256]         144
│    │    │    │    └─Tanh: 5-16                   [1, 72, 128, 256]         --
│    │    │    └─ConvNormActivation: 4-7           [1, 72, 128, 256]         --
│    │    │    │    └─Conv2d: 5-17                 [1, 72, 128, 256]         648
│    │    │    │    └─BatchNorm2d: 5-18            [1, 72, 128, 256]         144
│    │    │    │    └─Tanh: 5-19                   [1, 72, 128, 256]         --
│    │    │    └─ConvNormActivation: 4-8           [1, 24, 128, 256]         --
│    │    │    │    └─Conv2d: 5-20                 [1, 24, 128, 256]         1,728
│    │    │    │    └─BatchNorm2d: 5-21            [1, 24, 128, 256]         48
│    └─InvertedResidual: 2-5                       [1, 40, 64, 128]          --
│    │    └─Sequential: 3-7                        [1, 40, 64, 128]          --
│    │    │    └─ConvNormActivation: 4-9           [1, 72, 128, 256]         --
│    │    │    │    └─Conv2d: 5-22                 [1, 72, 128, 256]         1,728
│    │    │    │    └─BatchNorm2d: 5-23            [1, 72, 128, 256]         144
│    │    │    │    └─Tanh: 5-24                   [1, 72, 128, 256]         --
│    │    │    └─ConvNormActivation: 4-10          [1, 72, 64, 128]          --
│    │    │    │    └─Conv2d: 5-25                 [1, 72, 64, 128]          1,800
│    │    │    │    └─BatchNorm2d: 5-26            [1, 72, 64, 128]          144
│    │    │    │    └─Tanh: 5-27                   [1, 72, 64, 128]          --
│    │    │    └─SqueezeExcitation: 4-11           [1, 72, 64, 128]          --
│    │    │    │    └─AdaptiveAvgPool2d: 5-28      [1, 72, 1, 1]             --
│    │    │    │    └─Conv2d: 5-29                 [1, 24, 1, 1]             1,752
│    │    │    │    └─Tanh: 5-30                   [1, 24, 1, 1]             --
│    │    │    │    └─Conv2d: 5-31                 [1, 72, 1, 1]             1,800
│    │    │    │    └─Hardsigmoid: 5-32            [1, 72, 1, 1]             --
│    │    │    └─ConvNormActivation: 4-12          [1, 40, 64, 128]          --
│    │    │    │    └─Conv2d: 5-33                 [1, 40, 64, 128]          2,880
│    │    │    │    └─BatchNorm2d: 5-34            [1, 40, 64, 128]          80
│    └─InvertedResidual: 2-6                       [1, 40, 64, 128]          --
│    │    └─Sequential: 3-8                        [1, 40, 64, 128]          --
│    │    │    └─ConvNormActivation: 4-13          [1, 120, 64, 128]         --
│    │    │    │    └─Conv2d: 5-35                 [1, 120, 64, 128]         4,800
│    │    │    │    └─BatchNorm2d: 5-36            [1, 120, 64, 128]         240
│    │    │    │    └─Tanh: 5-37                   [1, 120, 64, 128]         --
│    │    │    └─ConvNormActivation: 4-14          [1, 120, 64, 128]         --
│    │    │    │    └─Conv2d: 5-38                 [1, 120, 64, 128]         3,000
│    │    │    │    └─BatchNorm2d: 5-39            [1, 120, 64, 128]         240
│    │    │    │    └─Tanh: 5-40                   [1, 120, 64, 128]         --
│    │    │    └─SqueezeExcitation: 4-15           [1, 120, 64, 128]         --
│    │    │    │    └─AdaptiveAvgPool2d: 5-41      [1, 120, 1, 1]            --
│    │    │    │    └─Conv2d: 5-42                 [1, 32, 1, 1]             3,872
│    │    │    │    └─Tanh: 5-43                   [1, 32, 1, 1]             --
│    │    │    │    └─Conv2d: 5-44                 [1, 120, 1, 1]            3,960
│    │    │    │    └─Hardsigmoid: 5-45            [1, 120, 1, 1]            --
│    │    │    └─ConvNormActivation: 4-16          [1, 40, 64, 128]          --
│    │    │    │    └─Conv2d: 5-46                 [1, 40, 64, 128]          4,800
│    │    │    │    └─BatchNorm2d: 5-47            [1, 40, 64, 128]          80
│    └─InvertedResidual: 2-7                       [1, 40, 64, 128]          --
│    │    └─Sequential: 3-9                        [1, 40, 64, 128]          --
│    │    │    └─ConvNormActivation: 4-17          [1, 120, 64, 128]         --
│    │    │    │    └─Conv2d: 5-48                 [1, 120, 64, 128]         4,800
│    │    │    │    └─BatchNorm2d: 5-49            [1, 120, 64, 128]         240
│    │    │    │    └─Tanh: 5-50                   [1, 120, 64, 128]         --
│    │    │    └─ConvNormActivation: 4-18          [1, 120, 64, 128]         --
│    │    │    │    └─Conv2d: 5-51                 [1, 120, 64, 128]         3,000
│    │    │    │    └─BatchNorm2d: 5-52            [1, 120, 64, 128]         240
│    │    │    │    └─Tanh: 5-53                   [1, 120, 64, 128]         --
│    │    │    └─SqueezeExcitation: 4-19           [1, 120, 64, 128]         --
│    │    │    │    └─AdaptiveAvgPool2d: 5-54      [1, 120, 1, 1]            --
│    │    │    │    └─Conv2d: 5-55                 [1, 32, 1, 1]             3,872
│    │    │    │    └─Tanh: 5-56                   [1, 32, 1, 1]             --
│    │    │    │    └─Conv2d: 5-57                 [1, 120, 1, 1]            3,960
│    │    │    │    └─Hardsigmoid: 5-58            [1, 120, 1, 1]            --
│    │    │    └─ConvNormActivation: 4-20          [1, 40, 64, 128]          --
│    │    │    │    └─Conv2d: 5-59                 [1, 40, 64, 128]          4,800
│    │    │    │    └─BatchNorm2d: 5-60            [1, 40, 64, 128]          80
│    └─InvertedResidual: 2-8                       [1, 80, 32, 64]           --
│    │    └─Sequential: 3-10                       [1, 80, 32, 64]           --
│    │    │    └─ConvNormActivation: 4-21          [1, 240, 64, 128]         --
│    │    │    │    └─Conv2d: 5-61                 [1, 240, 64, 128]         9,600
│    │    │    │    └─BatchNorm2d: 5-62            [1, 240, 64, 128]         480
│    │    │    │    └─Hardswish: 5-63              [1, 240, 64, 128]         --
│    │    │    └─ConvNormActivation: 4-22          [1, 240, 32, 64]          --
│    │    │    │    └─Conv2d: 5-64                 [1, 240, 32, 64]          2,160
│    │    │    │    └─BatchNorm2d: 5-65            [1, 240, 32, 64]          480
│    │    │    │    └─Hardswish: 5-66              [1, 240, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-23          [1, 80, 32, 64]           --
│    │    │    │    └─Conv2d: 5-67                 [1, 80, 32, 64]           19,200
│    │    │    │    └─BatchNorm2d: 5-68            [1, 80, 32, 64]           160
│    └─InvertedResidual: 2-9                       [1, 80, 32, 64]           --
│    │    └─Sequential: 3-11                       [1, 80, 32, 64]           --
│    │    │    └─ConvNormActivation: 4-24          [1, 200, 32, 64]          --
│    │    │    │    └─Conv2d: 5-69                 [1, 200, 32, 64]          16,000
│    │    │    │    └─BatchNorm2d: 5-70            [1, 200, 32, 64]          400
│    │    │    │    └─Hardswish: 5-71              [1, 200, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-25          [1, 200, 32, 64]          --
│    │    │    │    └─Conv2d: 5-72                 [1, 200, 32, 64]          1,800
│    │    │    │    └─BatchNorm2d: 5-73            [1, 200, 32, 64]          400
│    │    │    │    └─Hardswish: 5-74              [1, 200, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-26          [1, 80, 32, 64]           --
│    │    │    │    └─Conv2d: 5-75                 [1, 80, 32, 64]           16,000
│    │    │    │    └─BatchNorm2d: 5-76            [1, 80, 32, 64]           160
│    └─InvertedResidual: 2-10                      [1, 80, 32, 64]           --
│    │    └─Sequential: 3-12                       [1, 80, 32, 64]           --
│    │    │    └─ConvNormActivation: 4-27          [1, 184, 32, 64]          --
│    │    │    │    └─Conv2d: 5-77                 [1, 184, 32, 64]          14,720
│    │    │    │    └─BatchNorm2d: 5-78            [1, 184, 32, 64]          368
│    │    │    │    └─Hardswish: 5-79              [1, 184, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-28          [1, 184, 32, 64]          --
│    │    │    │    └─Conv2d: 5-80                 [1, 184, 32, 64]          1,656
│    │    │    │    └─BatchNorm2d: 5-81            [1, 184, 32, 64]          368
│    │    │    │    └─Hardswish: 5-82              [1, 184, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-29          [1, 80, 32, 64]           --
│    │    │    │    └─Conv2d: 5-83                 [1, 80, 32, 64]           14,720
│    │    │    │    └─BatchNorm2d: 5-84            [1, 80, 32, 64]           160
│    └─InvertedResidual: 2-11                      [1, 80, 32, 64]           --
│    │    └─Sequential: 3-13                       [1, 80, 32, 64]           --
│    │    │    └─ConvNormActivation: 4-30          [1, 184, 32, 64]          --
│    │    │    │    └─Conv2d: 5-85                 [1, 184, 32, 64]          14,720
│    │    │    │    └─BatchNorm2d: 5-86            [1, 184, 32, 64]          368
│    │    │    │    └─Hardswish: 5-87              [1, 184, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-31          [1, 184, 32, 64]          --
│    │    │    │    └─Conv2d: 5-88                 [1, 184, 32, 64]          1,656
│    │    │    │    └─BatchNorm2d: 5-89            [1, 184, 32, 64]          368
│    │    │    │    └─Hardswish: 5-90              [1, 184, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-32          [1, 80, 32, 64]           --
│    │    │    │    └─Conv2d: 5-91                 [1, 80, 32, 64]           14,720
│    │    │    │    └─BatchNorm2d: 5-92            [1, 80, 32, 64]           160
│    └─InvertedResidual: 2-12                      [1, 112, 32, 64]          --
│    │    └─Sequential: 3-14                       [1, 112, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-33          [1, 480, 32, 64]          --
│    │    │    │    └─Conv2d: 5-93                 [1, 480, 32, 64]          38,400
│    │    │    │    └─BatchNorm2d: 5-94            [1, 480, 32, 64]          960
│    │    │    │    └─Hardswish: 5-95              [1, 480, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-34          [1, 480, 32, 64]          --
│    │    │    │    └─Conv2d: 5-96                 [1, 480, 32, 64]          4,320
│    │    │    │    └─BatchNorm2d: 5-97            [1, 480, 32, 64]          960
│    │    │    │    └─Hardswish: 5-98              [1, 480, 32, 64]          --
│    │    │    └─SqueezeExcitation: 4-35           [1, 480, 32, 64]          --
│    │    │    │    └─AdaptiveAvgPool2d: 5-99      [1, 480, 1, 1]            --
│    │    │    │    └─Conv2d: 5-100                [1, 120, 1, 1]            57,720
│    │    │    │    └─Tanh: 5-101                  [1, 120, 1, 1]            --
│    │    │    │    └─Conv2d: 5-102                [1, 480, 1, 1]            58,080
│    │    │    │    └─Hardsigmoid: 5-103           [1, 480, 1, 1]            --
│    │    │    └─ConvNormActivation: 4-36          [1, 112, 32, 64]          --
│    │    │    │    └─Conv2d: 5-104                [1, 112, 32, 64]          53,760
│    │    │    │    └─BatchNorm2d: 5-105           [1, 112, 32, 64]          224
│    └─InvertedResidual: 2-13                      [1, 112, 32, 64]          --
│    │    └─Sequential: 3-15                       [1, 112, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-37          [1, 672, 32, 64]          --
│    │    │    │    └─Conv2d: 5-106                [1, 672, 32, 64]          75,264
│    │    │    │    └─BatchNorm2d: 5-107           [1, 672, 32, 64]          1,344
│    │    │    │    └─Hardswish: 5-108             [1, 672, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-38          [1, 672, 32, 64]          --
│    │    │    │    └─Conv2d: 5-109                [1, 672, 32, 64]          6,048
│    │    │    │    └─BatchNorm2d: 5-110           [1, 672, 32, 64]          1,344
│    │    │    │    └─Hardswish: 5-111             [1, 672, 32, 64]          --
│    │    │    └─SqueezeExcitation: 4-39           [1, 672, 32, 64]          --
│    │    │    │    └─AdaptiveAvgPool2d: 5-112     [1, 672, 1, 1]            --
│    │    │    │    └─Conv2d: 5-113                [1, 168, 1, 1]            113,064
│    │    │    │    └─Tanh: 5-114                  [1, 168, 1, 1]            --
│    │    │    │    └─Conv2d: 5-115                [1, 672, 1, 1]            113,568
│    │    │    │    └─Hardsigmoid: 5-116           [1, 672, 1, 1]            --
│    │    │    └─ConvNormActivation: 4-40          [1, 112, 32, 64]          --
│    │    │    │    └─Conv2d: 5-117                [1, 112, 32, 64]          75,264
│    │    │    │    └─BatchNorm2d: 5-118           [1, 112, 32, 64]          224
│    └─InvertedResidual: 2-14                      [1, 160, 32, 64]          --
│    │    └─Sequential: 3-16                       [1, 160, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-41          [1, 672, 32, 64]          --
│    │    │    │    └─Conv2d: 5-119                [1, 672, 32, 64]          75,264
│    │    │    │    └─BatchNorm2d: 5-120           [1, 672, 32, 64]          1,344
│    │    │    │    └─Hardswish: 5-121             [1, 672, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-42          [1, 672, 32, 64]          --
│    │    │    │    └─Conv2d: 5-122                [1, 672, 32, 64]          16,800
│    │    │    │    └─BatchNorm2d: 5-123           [1, 672, 32, 64]          1,344
│    │    │    │    └─Hardswish: 5-124             [1, 672, 32, 64]          --
│    │    │    └─SqueezeExcitation: 4-43           [1, 672, 32, 64]          --
│    │    │    │    └─AdaptiveAvgPool2d: 5-125     [1, 672, 1, 1]            --
│    │    │    │    └─Conv2d: 5-126                [1, 168, 1, 1]            113,064
│    │    │    │    └─Tanh: 5-127                  [1, 168, 1, 1]            --
│    │    │    │    └─Conv2d: 5-128                [1, 672, 1, 1]            113,568
│    │    │    │    └─Hardsigmoid: 5-129           [1, 672, 1, 1]            --
│    │    │    └─ConvNormActivation: 4-44          [1, 160, 32, 64]          --
│    │    │    │    └─Conv2d: 5-130                [1, 160, 32, 64]          107,520
│    │    │    │    └─BatchNorm2d: 5-131           [1, 160, 32, 64]          320
│    └─InvertedResidual: 2-15                      [1, 160, 32, 64]          --
│    │    └─Sequential: 3-17                       [1, 160, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-45          [1, 960, 32, 64]          --
│    │    │    │    └─Conv2d: 5-132                [1, 960, 32, 64]          153,600
│    │    │    │    └─BatchNorm2d: 5-133           [1, 960, 32, 64]          1,920
│    │    │    │    └─Hardswish: 5-134             [1, 960, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-46          [1, 960, 32, 64]          --
│    │    │    │    └─Conv2d: 5-135                [1, 960, 32, 64]          24,000
│    │    │    │    └─BatchNorm2d: 5-136           [1, 960, 32, 64]          1,920
│    │    │    │    └─Hardswish: 5-137             [1, 960, 32, 64]          --
│    │    │    └─SqueezeExcitation: 4-47           [1, 960, 32, 64]          --
│    │    │    │    └─AdaptiveAvgPool2d: 5-138     [1, 960, 1, 1]            --
│    │    │    │    └─Conv2d: 5-139                [1, 240, 1, 1]            230,640
│    │    │    │    └─Tanh: 5-140                  [1, 240, 1, 1]            --
│    │    │    │    └─Conv2d: 5-141                [1, 960, 1, 1]            231,360
│    │    │    │    └─Hardsigmoid: 5-142           [1, 960, 1, 1]            --
│    │    │    └─ConvNormActivation: 4-48          [1, 160, 32, 64]          --
│    │    │    │    └─Conv2d: 5-143                [1, 160, 32, 64]          153,600
│    │    │    │    └─BatchNorm2d: 5-144           [1, 160, 32, 64]          320
│    └─InvertedResidual: 2-16                      [1, 160, 32, 64]          --
│    │    └─Sequential: 3-18                       [1, 160, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-49          [1, 960, 32, 64]          --
│    │    │    │    └─Conv2d: 5-145                [1, 960, 32, 64]          153,600
│    │    │    │    └─BatchNorm2d: 5-146           [1, 960, 32, 64]          1,920
│    │    │    │    └─Hardswish: 5-147             [1, 960, 32, 64]          --
│    │    │    └─ConvNormActivation: 4-50          [1, 960, 32, 64]          --
│    │    │    │    └─Conv2d: 5-148                [1, 960, 32, 64]          24,000
│    │    │    │    └─BatchNorm2d: 5-149           [1, 960, 32, 64]          1,920
│    │    │    │    └─Hardswish: 5-150             [1, 960, 32, 64]          --
│    │    │    └─SqueezeExcitation: 4-51           [1, 960, 32, 64]          --
│    │    │    │    └─AdaptiveAvgPool2d: 5-151     [1, 960, 1, 1]            --
│    │    │    │    └─Conv2d: 5-152                [1, 240, 1, 1]            230,640
│    │    │    │    └─Tanh: 5-153                  [1, 240, 1, 1]            --
│    │    │    │    └─Conv2d: 5-154                [1, 960, 1, 1]            231,360
│    │    │    │    └─Hardsigmoid: 5-155           [1, 960, 1, 1]            --
│    │    │    └─ConvNormActivation: 4-52          [1, 160, 32, 64]          --
│    │    │    │    └─Conv2d: 5-156                [1, 160, 32, 64]          153,600
│    │    │    │    └─BatchNorm2d: 5-157           [1, 160, 32, 64]          320
│    └─ConvNormActivation: 2-17                    [1, 960, 32, 64]          --
│    │    └─Conv2d: 3-19                           [1, 960, 32, 64]          153,600
│    │    └─BatchNorm2d: 3-20                      [1, 960, 32, 64]          1,920
│    │    └─Hardswish: 3-21                        [1, 960, 32, 64]          --
├─LRASPPHead: 1-2                                  [1, 20, 64, 128]          --
│    └─Sequential: 2-18                            [1, 128, 32, 64]          --
│    │    └─Conv2d: 3-22                           [1, 128, 32, 64]          122,880
│    │    └─BatchNorm2d: 3-23                      [1, 128, 32, 64]          256
│    │    └─Tanh: 3-24                             [1, 128, 32, 64]          --
│    └─Sequential: 2-19                            [1, 128, 1, 1]            --
│    │    └─AdaptiveAvgPool2d: 3-25                [1, 960, 1, 1]            --
│    │    └─Conv2d: 3-26                           [1, 128, 1, 1]            122,880
│    │    └─Sigmoid: 3-27                          [1, 128, 1, 1]            --
│    └─Conv2d: 2-20                                [1, 20, 64, 128]          820
│    └─Conv2d: 2-21                                [1, 20, 64, 128]          2,580
====================================================================================================
Total params: 3,221,368
Trainable params: 3,221,368
Non-trainable params: 0
Total mult-adds (G): 3.95
====================================================================================================
Input size (MB): 6.29
Forward/backward pass size (MB): 888.71
Params size (MB): 12.89
Estimated Total Size (MB): 907.89
====================================================================================================
